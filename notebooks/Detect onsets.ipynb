{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58a6feaf",
   "metadata": {},
   "source": [
    "# This notebook demonstrates how to extract onset features from the audio files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54843a1",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b108bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.path.join(\"..\", \"src\"))\n",
    "\n",
    "from data_loader import GmdDataLoader\n",
    "from feat_extractor import DrumFreqFeatExtractor\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7baf05",
   "metadata": {},
   "source": [
    "### Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0cc6f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_path = os.path.join(\"..\", \"data\")\n",
    "dataset_root_path = os.path.join(data_root_path, \"groove\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c0af88",
   "metadata": {},
   "source": [
    "### Define constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1817a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_duration = 30.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af1b8e6",
   "metadata": {},
   "source": [
    "### Create generator for audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "groove_data_loader = GmdDataLoader(dataset_root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf36c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = groove_data_loader.get_data(split=GmdDataLoader.TRAIN_SPLIT, min_duration=min_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2117e93b",
   "metadata": {},
   "source": [
    "### Get dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe42253",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_n = groove_data_loader.get_dataset_size()\n",
    "original_train_n = groove_data_loader.get_dataset_size(split=\"train\")\n",
    "original_test_n = groove_data_loader.get_dataset_size(split=\"test\")\n",
    "print(\"Number of samples before discarding stage - Total samples: {} - Training samples: {} - Test samples: {}\"\n",
    "     .format(original_n, original_train_n, original_test_n))\n",
    "original_n = groove_data_loader.get_dataset_size(min_duration = min_duration)\n",
    "original_train_n = groove_data_loader.get_dataset_size(split=\"train\", min_duration = min_duration)\n",
    "original_test_n = groove_data_loader.get_dataset_size(split=\"test\", min_duration = min_duration)\n",
    "print(\"Number of samples after discarding stage - Total samples: {} - Training samples: {} - Test samples: {}\"\n",
    "     .format(original_n, original_train_n, original_test_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3770161",
   "metadata": {},
   "source": [
    "### Play one of the training audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea30d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, meta_data, start_time = next(train_data_generator)\n",
    "print(\"First beat detected on {}\".format(start_time))\n",
    "print(\"Sampling rate: {}\".format(groove_data_loader.sr))\n",
    "IPython.display.Audio(data=y, rate=groove_data_loader.sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc51d37",
   "metadata": {},
   "source": [
    "### Extract onset features from training audio file and visualize them\n",
    "\n",
    "We use STFT and calculate the spectral difference in separate frequency bands. Then we use the same approach as in Hainsworth where a variable size matrix H is used to transform observations to states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee5e6a",
   "metadata": {},
   "source": [
    "#### Visualize waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694f5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Audio recording waveform\")\n",
    "plt.plot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec4ef7b",
   "metadata": {},
   "source": [
    "#### Extract onset features\n",
    "\n",
    "Short-time-fourier-transform -> Split frequencies in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8a3298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
